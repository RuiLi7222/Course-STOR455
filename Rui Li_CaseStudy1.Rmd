---
title: 'Case Study 1: College Basketball'
author: "prepared by Kelly Bodwin"
output: html_document
---

In this Case Study, you will refresh your memory of STOR 155 while you learn some basic commands and tools for analyzing data with **R**.  We'll be looking at some data from college basketball games in 2015.

Run the following **R** code to load the data into your RStudio and take a look at it.

## Summarizing data

```{r, eval = TRUE}
# Load dataset
bball = read.csv("http://kbodwin.web.unc.edu/files/2016/06/basketball.csv")

# Look at dataset
head(bball)
summary(bball)
tail(bball)
ncol(bball)
nrow(bball)
ncol(head(bball))
ncol(summary(bball))
ncol(tail(bball))
nrow(head(bball))
nrow(summary(bball))
nrow(tail(bball))
```

The command `read.csv( )` will read a dataset into R from your computer or from online.  "csv" stands for "comma separated value", a common file type where the data is listed in a text file, with variables separated by commas.  For now, you don't need to worry about the details of `read.csv( )`.  Once you have loaded the data, the command `summary( )` will tell you about the variables in the dataset and their values.  Another useful function is `head( )`, which shows you the first 6 rows of the dataset.
***
### Question 1:

a) Look at the outputs of `summary(bball)` and `head(bball)`, and describe the variables using vocabulary from STOR 155. 
```
The 'head(bball)' shows the first six smaples in the data set. The quantitative varaibles are "X", "Team Score", and "Opponent Score", while the qualitative variables are "Date", "Team", "Team Location", "Opponent", and "Team Result".
The 'summary(bball)' summarizes all data in each variable. As for the quantitative varaibles, the 'summary(bball)' uses "Mins.", "1st Qu.", "Median", "Mean", "3rd Qu.", and "Max." to describe. As for the qualitative variables, the 'summary(bball)' calculates the total number of each category in one varaible.
```
b) If `head( )` shows the first 6 rows of the dataset, what command do you think might show the *last* 6 rows?  Try out your proposed function and see what happens
```
The command 'tail( )' shows the last 6 rows of data.
```
c) Try the commands `ncol( )` and `nrow( )`.  What do these do?  How could you get the same information from `head( )`, `summary( )`, and/or the command you figured out in part (b)?
```
The command 'ncol( )' is to calculate the number of columns of the data, while the command 'nrow' calculates the number of rows of the same data.
As shown in the output, the 'ncol(bball)' = 'ncol(head(bball))' = 'ncol(summary(bball))' = 'ncol(tail(bball))' = 8. It shows that 'head(bball)', 'summary(bball)', and 'tail(bball)' have the same number of columns(variables).
```
***

Sometimes, we will want to look at individual entries, rows, or columns of our data matrix.  We can do this using brackets `[ ]` after our dataset.  We can also look at a variables (columns) by name using the *$* symbol.  Try the following examples.

```{r, eval = TRUE}
# Look at a single row
bball[123, ]
```
```{r, eval = FALSE}
# Look at a single column
bball[ , 5]
bball$Team.Score
```
```{r, eval = TRUE}
# Look at a single entry
bball[123, 5]
bball$Team.Score[123]

# Calculate mean, median, variance, and standard deviation
mean(bball$Team.Score)
mean(bball[,5])
median(bball$Team.Score)
var(bball$Team.Score)
sd(bball$Team.Score)

```

***

### Question 2:

a) What is the difference between `mean(bball$Team.Score)` and `mean(bball[,5])`?  Why might it be useful to have two ways to get access the variable `Team.Score`?
```
There is no difference between `mean(bball$Team.Score)` and `mean(bball[,5])`. Both varaibles discribe the mean value of 'Team Score' column. 
When there are too much columns, it's very difficult to define the exact number of the column. In this case, using '$' symbol would be a better choice. When there are a few columns, using [ ] is much more convenient, because you do not have to type the name of the column, and a number will work.
```
b) In plain English, what were the events of the game represented by the first row of the dataset?
```
On 11/13/15, Team Old Dominion defeated Niagara at neutral place (neither home nor away game). Team Old Dominion scored 67, while Niagara scored 50.
```
*(Note:  If you don't know much about basketball - for example, if you don't know what it means to play a game "Home" versus "Away" - ask people around you.)*

***


All these commands we have been using, like `summary( )` and `mean( )` are called *functions*.  A function can take all different kinds of input depending on what you are trying to do: datasets, vectors such as `bball$Team.Score`, etc. An important skill in **R** is figuring out for yourself how functions work.

For example, type `?boxplot` into your **R** console.  A help page will pop up telling you about this function.  Notice that under **Usage**, it says `boxplot(x, ...)`.  This tells you that you need to supply something called *x* to the function, and the rest of the input is optional.  But what is *x*?  Ah-ha!  There is a section called **Arguments**, which tells us that *x* is the vector of values you want to put in a boxplot.

Run the code below to make a boxplot of the team scores of college basketball games.

```{r, eval = TRUE}

# make boxplot of team scores
boxplot(bball$Team.Score)

```


***

### Question 3: 

a) Now check out `?hist`, a function for making histograms.  Below is basic code to make a histogram of `Team.Scores`, and also code for the same histogram but with a lot of the optional input changed.  Mess around with these inputs until you understand what each is doing.   

```{r, eval = TRUE}

# Boring histogram
hist(bball$Team.Score)

# Fancy histogram
hist(bball$Team.Score, breaks = 5, main = "I am a title", xlab = "I am an x-axis label", col = "grey", freq = FALSE)

```
Explain in your own words what `breaks` and `freq` change about the histogram.
```
The 'breaks' resets the numbers of groups in histogram.
The 'freq' changes frequency histogram to density histogram.
```
b) The optional inputs `main`, `xlab`, `ylab`, and `col` are common to most plotting functions.  Use what you learned in (a) to make a boxplot of `Team.Scores` with proper axis labels and title.

```{r, eval = TRUE}

# make boxplot of team scores
boxplot(bball$Team.Score, main = "The boxplot of bball$Team.Score", xlab = "bball$Team.Score", ylab = "Team Score Value", col = "purple")

```

c) To check if the histogram is Normal, or to help visualize its shape, we might want to overlay a Normal curve on top of the histogram.  The code below will do so - but the curve doesn't fit very well.  
```{r, eval = TRUE}

# Boring histogram
hist(bball$Team.Score, freq = FALSE)

# overlay Normal Curve

curve(dnorm(x, mean=120, sd=20), 
      add = TRUE, col = "blue", lwd = 2)
```
Explain what the role is of the functions `curve( )` and `dnorm( )`.  Why did we put `add = TRUE` in the inputs?
```
The 'curve( )' is used to curve a function, and the 'dnorm' is to describe the probability density function of normal distribution.

If we put 'add = TRUE' here, it means the new cruve will be shown together with the former histogram. That is to say the new curve will overlay the histogram.
```
d) Alternatively, we can overlay a line that is a "smoothed" version of the data, as follows:

```{r, eval = TRUE}
plot(density(bball$Team.Score)$x,density(bball$Team.Score)$y)
hist(bball$Team.Score, freq = FALSE)
# overlay smoothed curve
lines(density(bball$Team.Score)$x,density(bball$Team.Score)$y, col = "red", lwd = 2, lty = 2)
```

What is the difference between `lines( )` and `curve( )`?  When might we want to use `density( )`, and when would it be better to overlay a Normal curve on a histogram?
```
The 'lines( )' needs the exact x,y to be operated, and 'plot( )' is needed before running 'lines( )'. It defaults new line overlay the original one. The 'curve' describes a function and does not default new curve overlay the original one. That is why 'add (TRUE)' is needed in 'curve( )'. 

We use 'density( )' when we want to know the spreading distribution of a data collection or more information about the the data set. When we want to compare the histogram and the curve so as to know wether we get the correct mean and sd., we will overlay a Normal curve on a histogram. 
```


e)  Now make your own histogram with well-chosen inputs and with a Normal overlay that fits better.  Would you say the data looks Normal?

```{r, eval = TRUE}
hist(bball$Team.Score, freq = FALSE)
curve(dnorm(x, mean(bball$Team.Score), sd(bball$Team.Score)), add = TRUE, col = "Green", lwd = 3)
qqnorm(bball$Team.Score)
```
```
The data looks Normal, because the histogram and curve are normally distributed, and the Q-Q plot is approximately linear.
```
***

## Subsetting

One of the most powerful qualities of **R** is the ability to select a subset of a dataset. Suppose we want to look only at games involving UNC or Duke.  We would need to figure out which rows of `bball` involve one of those teams, and then make a new dataset out of only those rows.  

For this, we will use *booleans*, which are variables with the value `TRUE` or `FALSE`.  Play around with the following code until you feel comfortable with `==`, `>`, `<`, and `%in%` as well as `&` (and) and `|` (or).

```{r, eval = FALSE}
# booleans practice

1 == 1
1 == 2
1 < 2

1 == 1 | 1  > 2
1 == 1 & 1 > 2

```

You can make up your own vector using the function `c( )`, which stands for "concatenate".  This is like making a new variable - the variable can contain anything you want, such as numbers, strings, booleans. Try the example below to make a vector and subset it. Note that we can use either `<-` or `=` to store information in a variable.

```{r, eval = FALSE}

vec <- c("cat", "dog", "horned toad", "Her Majesty Queen Elizabeth", "dog")
vec

# Some more booleans
vec == "dog"
"dog" == vec
vec %in% c("dog", "cat")
c("dog", "cat") %in% vec


# Finding indices

which(vec == "dog")
which(vec %in% c("dog", "cat"))
which(c("dog", "cat") %in% vec)

# Subsetting
new = vec[vec %in% c("dog", "cat")]
new

```

***

### Question 4:

a) The following code will give you an error.  What happened?
```{r, eval = FALSE}

vec = c(1, 2, 3, "4")
vec + 2

```
```
The "4" turns 'c( )' into a string vector. Therefore, the "vec" is a character string vector, and cannot calculate with numbers.
```

b) The following code will NOT give you an error?  What is going on here?
```{r, eval = FALSE}

vec = c(TRUE, FALSE, FALSE, TRUE)
vec + 2

```
```
Here, the "vec" is a logical vector. A logical vector can calculate with numbers, while TRUE == 1, and FALSE == 0. 
```

c) Now we are ready to make a new dataset.  We'll get a list of booleans to tell us where UNC or Duke's games are, and use that to subset the datset `bball`.

Try running each of the following lines of code.  None of them will make the datset we want.  What was the problem with each one?

```{r, eval = FALSE}

# Make new dataset with only UNC or Duke games


#A
my_subset = bball[Team == "North Carolina" | Team == "Duke", ]

#B
my_subset = bball[bball$Team == "North Carolina", bball$Team == "Duke"]

#C
my_subset = bball[bball$Team = "North Carolina" | bball$Team = "Duke", ]

#D
my_subset = bball[bball$Team == "North Carolina" & bball$Team == "Duke", ]

#E
unc_games = which(bball$Team == "North Carolina")
my_subset = bball[unc_games | bball$Team == "Duke", ]

#F
my_subset = bball[bball$Team == "North Carolina" | bball$Team == "Duke"]

```

```
Respectively, There are some problems of each code.
  A: Column "Team" should be selected using symbol "$", or "[,]".
  B: The comma "," should be printed behind "Duke", because variable "Team" is on a column not on a row. Also, "|" should be put between "North Carolina" and "Duke".
  C: The symbol "=" inside the "[,]" should be replaced with "==". While the former one is used to assign value, the latter one is for logical judging.
  D: The symbol "&" should be replaced with ¡°|¡±£¬because we want dataset including "North Carolina" or "Duke".
  E: While 'unc_games' is a numerical vector, the 'bball$Team == "Duke"' is a logical vector. They cannot be operated with "|".
  F: The code needs a comma "," behind "Duke".
```

d) Now write your own code to make the correct dataset.

```{r, eval = TRUE}

my_subset = bball[bball$Team == "North Carolina" | bball$Team == "Duke", ]
```

***

## Z-Scores and t-scores

Alright, enough of that data wrangling.  Time to do some statistics.

Check out `?Normal`.  These are some functions that will help us calculate probabilities about the Normal distribution. (No more using Table A!)  The most important ones are `pnorm` and `qnorm`.

`pnorm(q)` will tell you the probability of a standard Normal being below the value `q`

`qnorm(p)` will tell you the z-score that has area `p` below it on a standard Normal curve

***

### Question 5

a) For each of the following lines of code, think about what the result will be **before** running the code.  **Draw a picture for each one to visualize what is going on with `pnorm` and `qnorm`.**

```{r, eval = TRUE}
# practice with Normal densities in R

#i
pnorm(0)
x=seq(-4,4,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")
x=seq(-4,0,length=200)
y=dnorm(x, mean = 0, sd=1)
polygon(c(-4,x,0),c(0,y,0),col="gray")

qnorm(0)
x=seq(-4,4,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")

#ii
pnorm(100)
x=seq(-4,100,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")
x=seq(-4,100,length=200)
y=dnorm(x, mean = 0, sd=1)
polygon(c(-4,x,100),c(0,y,0),col="gray")

qnorm(100)
x=seq(-4,4,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")

#iii
qnorm(pnorm(0))
x=seq(-4,4,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")
x=seq(-4,qnorm(pnorm(0)),length=200)
y=dnorm(x, mean = 0, sd=1)
polygon(c(-4,x,qnorm(pnorm(0))),c(0,y,0),col="gray")

qnorm(pnorm(7))
x=seq(-2,8,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")
x=seq(-2,qnorm(pnorm(7)),length=200)
y=dnorm(x, mean = 0, sd=1)
polygon(c(-2,x,qnorm(pnorm(7))),c(-2,y,0),col="gray")

#iv
pnorm(qnorm(0))
x=seq(-2,2,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")

pnorm(qnorm(0.5))
x=seq(-4,4,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")
x=seq(-4,qnorm(0.5),length=200)
y=dnorm(x, mean = 0, sd=1)
polygon(c(-4,x,qnorm(0.5)),c(0,y,0),col="gray")

#v
pnorm(0, sd = 10)
x=seq(-4,4,length=200)
y=dnorm(x, mean = 0, sd=10)
plot(x,y,type="l", lwd=2, col="blue", main = "Normal Distribution")
x=seq(-4,0,length=200)
y=dnorm(x, mean = 0, sd=10)
polygon(c(-4,x,0),c(0,y,0),col="gray")

pnorm(0, mean = 1, sd = 10)
x=seq(-4,6,length=200)
y=dnorm(x, mean = 1, sd=10)
plot(x,y,type="l", lwd=2, col="blue", main = "Normal Distribution")
x=seq(-4,0,length=200)
y=dnorm(x, mean = 1, sd=10)
polygon(c(-4,x,0),c(0,y,0),col="gray")

#vi
qnorm(0.05)
x=seq(-2,2,length=200)
y=dnorm(x, mean = 0, sd=1)
plot(x,y,type="l", lwd=2, col="blue", main = "Standard Normal Distribution")
x=seq(-2,qnorm(0.05),length=200)
y=dnorm(x, mean = 0, sd=1)
polygon(c(-2,x,qnorm(0.05)),c(-2,y,0),col="gray")

qnorm(0.05, sd = 10)
x=seq(-20,-10,length=200)
y=dnorm(x, mean = 0, sd=10)
plot(x,y,type="l", lwd=2, col="blue", main = "Normal Distribution")
x=seq(-20,qnorm(0.05, sd = 10),length=200)
y=dnorm(x, mean = 0, sd=10)
polygon(c(-20,x,qnorm(0.05, sd = 10)),c(-20,y,0),col="gray")

qnorm(0.05, mean = 1, sd = 10)
x=seq(-20,-10,length=200)
y=dnorm(x, mean = 1, sd=10)
plot(x,y,type="l", lwd=2, col="blue", main = "Normal Distribution")
x=seq(-20,qnorm(0.05, mean = 1, sd = 10),length=200)
y=dnorm(x, mean = 1, sd=10)
polygon(c(-20,x,qnorm(0.05, mean = 1, sd = 10)),c(-20,y,0),col="gray")
```

b) Why did you get an error in part (ii)?
```
The "p" shows the percentage or probability you want to get a z-score value. Therefore, qnorm(p)'s inputs must be a probability (value between 0 and 1). But here we get p == 100, which is much larger than 1.
```

***

Now use this code to make a new variable for the total score of a game:

```{r, eval = TRUE}
# Make new variable
bball$Total.Score = bball$Team.Score + bball$Opponent.Score
```

We will use *z-scores* and *t-scores* to think about whether a game is unusually high scoring.

***

### Question 6:

a) As you may have noticed, the dataset `bball` actually displays each game twice: once for each team.  Make a new dataset with each game listed only once by subsetting `bball`.
```{r, eval = TRUE}
once_subset = bball[bball$Team.Result == "Win", ]
```

b) On Feb 17, 2016, UNC played Duke.  Using the Normal distribution, what percent of games have higher scores than the UNC/Duke game?  (Assume that the mean and standard deviation of `Team.Score` are actually the *population* mean and standard deviation.)  
```{r, eval = TRUE}
Normal_approximation = pnorm(147, mean(once_subset$Total.Score), sd(once_subset$Total.Score), lower.tail = FALSE)
print(Normal_approximation)
```

c) What percentage of games in the dataset did we observe to be higher scoring than the UNC/Duke game?  The functions `sum( )` and `length( )` will help you answer this question.

```{r, eval = TRUE}
higher_scoring = sum(once_subset$Total.Score > 147, na.rm = FALSE)
total_scoring = length(once_subset$Total.Score)
observation_percentage = higher_scoring/total_scoring
print(observation_percentage)
```

d)  What is the difference between what we did in (b) and (c)?  Do you think the Normal approximation is reasonable for this data?  Why or why not?
```
While Normal_approximation == 0.4611, the observation_percentage == 0.4360. 
The (b) assumes once_subset$Total.Score is Normal distributed, and using 'pnorm( )' (a Normal distribution method) to calculate the higher scoring percentage.
The (c) calculates the percentage of higher scoring teams directly by employing 'sum( )' and 'length( )' (Counting methods).
I think the Normal approximation is not reasonable for this data (0.4611 is not close to 0.4360), because the dataset (once_subset$Total.Score) is not strictly Normal distributed (the following Q-Q Plot is not perfectly linear).
```
```{r, eval = TRUE}
qqnorm(once_subset$Total.Score)
qqline(once_subset$Total.Score, col="red", lwd="3")
```
***

Recall that *t-scores* are used instead of *z-scores* when the population standard deviation is unknown.  The functions `pt` and `qt` work almost same way as `pnorm` and `qnorm`, but for the t-distribution instead of the Normal.  However, be careful, and read `?pt` for help!  These functions don't let you enter the mean and standard deviation as input - you need to figure out what do about that!

***

### Question 7:
Use all your new **R** skills to answer this question: Was the Feb 17th game between UNC and Duke particularly high scoring *for a UNC game*?

```{r, eval = TRUE}
UNC_subset = bball[bball$Team == "North Carolina", ]
n = length(UNC_subset$Total.Score)
df = n - 1
xbar = mean(UNC_subset$Total.Score)
s = sd(UNC_subset$Total.Score)
pt((xbar-147)/(s/sqrt(n)), df, lower.tail = FALSE)
```
```
I first accept the Feb 17th game between UNC and Duke particularly was high scoring for a UNC game.
H0: ¦Ì < 147
Ha: ¦Ì >= 147 
P-value = 0.039 < 0.05. 
It means there is strong evidence that supports the alternative hypothesis, ¦Ì >= 147. Therefore, the null hypothesis is wrong and the Feb 17th game between UNC and Duke was not particularly high scoring for a UNC game.  
```
***

## Confidence Intervals and Proportions

You now have all the **R** knowledge you need to make some confidence intervals!  You may wish to go over your lecture notes for this section, especially to remind yourself how to deal with proportions.

***

### Question 8:

a) Make a 95% confidence interval for the number of points UNC scores in a given game.  You will need to think about which **R** commands will give you critical values of the *t*-distribution, and how to use these to make a confidence interval.

```{r, eval = TRUE}
LowerLimit=mean(UNC_subset$Team.Score, na.rm = TRUE)-qt(.975,34-1)*sd(UNC_subset$Team.Score,na.rm = TRUE)/sqrt(34)
UpperLimit=mean(UNC_subset$Team.Score, na.rm = TRUE)+qt(.975,34-1)*sd(UNC_subset$Team.Score,na.rm = TRUE)/sqrt(34)
print(LowerLimit)
print(UpperLimit)
```
```
Based on these data, we are about 95% confident that the average points UNC scores in a given game is larger than 78.57 but lower than 85.96. 
```
b) What percentage of games did UNC win in 2015-2016?  Make a 95% confidence interval for their win percentage.


```{r, eval = TRUE}
x_UNC=sum(UNC_subset$Team.Result=="Win")
n_UNC=length(UNC_subset$Team.Result)
p=x_UNC/n_UNC
z=qnorm(.975)
SE=sqrt(p*(1-p)/n_UNC)
LowerLimit_p=p-z*SE
UpperLimit_p=p+z*SE
print(LowerLimit_p)
print(UpperLimit_p)
```
```
We are 95% confident that the percentage of games UNC won in 2015-2016 is between 0.695 and 0.952.
```
***

## Hypothesis Testing

You have now had lots of practice learning to use a function by reading the documentation.  Part of the point of this course is for you to become familiar enough with **R** to learn new commands and functions without being shown how to use them.  This will make you a skillful (and hireable!) programmer in the future.

Check out `?t.test` and `?prop.test`.  Figure out what these functions do, what input they take, etc. Then answer the following questions.

***

### Question 9:

a) Does UNC tend to win more games than they lose?  That is, is there evidence at the 0.05 level that the "true" probability of UNC winning a given game in 2015-2016 is larger than 0.5?

```{r, eval = TRUE}
prop.test(x_UNC, n_UNC, alternative = c("greater"), conf.level = 0.95, correct = TRUE)
```
```
Based on the data output above, p-value = 0.0001582 < 0.05. Therefore, there is 0.05 level evidence to reject the null hypothesis and support that the "true" probability of UNC winning a given game in 2015-2016 is larger than 0.5.
```
b) Based on how many points they tend to score in a game, would you say UNC and Yale were equally good teams? 

```{r, eval = TRUE}
Yale_subset=bball[bball$Team == "Yale", ]
t.test(UNC_subset$Team.Score, Yale_subset$Team.Score, alternative = c("greater"), mu=0, paired = FALSE, var.equal = FALSE, conf.level = 0.95)
```
```
Based on the data output above, p-value = 0.008 < 0.05, showing UNC and Yale have different mean scores. Therefore, there is 0.05 level evidence to reject the null hypothesis and support that UNC and Yale were not equally good teams. Also, the average scores of UNC is larger than those of Yale.
```

c) Based on win percentage, would you say UNC and Yale were equally good teams?  Discuss this result and the result in (b).

```{r, eval = TRUE}
x_UNC=sum(UNC_subset$Team.Result == "Win")
n_UNC=length(UNC_subset$Team.Result)
p_UNC=x_UNC/n_UNC
x_Yale=sum(Yale_subset$Team.Result == "Win")
n_Yale=length(Yale_subset$Team.Result == "Win")
p_Yale=x_Yale/n_Yale
prop.test(c(x_UNC, x_Yale), c(n_UNC, n_Yale), p = NULL, alternative = c("two.sided"), conf.level = 0.95, correct = TRUE)
```
```
Based on the data output above, p-value = 0.9585 > 0.05. Therefore, there is no evidence to reject the null hypothesis, and the win percentages of UNC and Yale are nearly the same. According to win percentage, UNC and Yale were equally good teams.
In (b), compared the team score value, UNC had highed scores than Yale, so UNC was a better team. However, in (c), compared the win percentage, there was no difference between two teams. That is to say UNC and Yale had nearly the same percentage to win a game, but UNC tended to have a higher score.
```

***
## Comparing multiple means (Analysis of Variance)

What if we want to compare more than one team? In lecture, you learned about using an Analysis of Variance (ANOVA) F-test to check if more than two means are equal.  We will use the function `aov( )` to find out if the big three North Carolina teams - UNC, Duke, and NC State - all tend to score the same number of points.

***
### Question 10
a) Make a dataset called `nc_games` that includes only games for the North Carolina teams, and then alter the code below to create a box plot of the scores for the three North Carolina teams.  Does it look like any of the means are significantly different?

```{r, eval = TRUE}
nc_games=bball[bball$Team == "North Carolina" | bball$Team == "Duke" | bball$Team == "North Carolina State", ]
boxplot(nc_games$Team.Score ~ factor(nc_games$Team), data=nc_games,  col="red", main="The boxplot of nc_games", ylab="Team Score Value")
```
```
Based on the boxplot above, the mean of North Carolina State is significant different from the other two teams.
```
b) Perform an ANOVA F-test on the means.  Interpret the output.  Is there evidence that the average scores of the three teams are not all equal?

```{r, eval = TRUE}
Ftest=aov(Team.Score ~ Team, data = nc_games)
summary(Ftest)
```
```
Based on the data output above, p-value = 0.0284 < 0.05, there is 0.05 level evidence to reject the null hypothesis. Therefore, there is 0.05 level evidence that not all average scores of the three teams are equal.
```

***